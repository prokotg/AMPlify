{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab09.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "082d021a10f242c1bedc807da13b2008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f57941c5e97403090ece9f37ae1ffbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f5d7a00e4a54f8c921c82d409224f5c",
              "IPY_MODEL_17e850ad96ae488c89a43ac12efac107"
            ]
          }
        },
        "1f57941c5e97403090ece9f37ae1ffbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f5d7a00e4a54f8c921c82d409224f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_452c6ae79c2746999de9c7be4efba04f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3257,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3257,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36987f380f4841f9ab461ad564504e57"
          }
        },
        "17e850ad96ae488c89a43ac12efac107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5225a5f45fde40c78b7a1921c9444ad5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3257/3257 [00:22&lt;00:00, 144.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a40d1ae790948f185e559e959a16da7"
          }
        },
        "452c6ae79c2746999de9c7be4efba04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36987f380f4841f9ab461ad564504e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5225a5f45fde40c78b7a1921c9444ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a40d1ae790948f185e559e959a16da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsITBHLCFCnJ"
      },
      "source": [
        "# Wstęp\n",
        "Zadanie 9 stanowi pierwszy z trzech etapów zajęć poświęconych sieciom rekurencyjnym i predykcji z wykorzystaniem danych multimodalnych. Efektem wszystkich trzech etapów będzie sieć rekurencyjna z warstwą atencji do predykcji kursu kryptowaluty Bitcoin (BTC) w oparciu o dane z giełdy oraz o wyniki analizy emocji komunikatów z mediów społecznościowych, do których również należy utworzyć dedykowany model sieci rekurencyjnej. Plan realizacji etapów wygląda następująco:\n",
        "\n",
        "1.   EmoTweet - model sieci rekurencyjnej do analizy emocji \n",
        "2.   MultiBTC - multimodalny model sieci rekurencyjnej do predykcji kursu BTC\n",
        "3.   AttEmoTweet & AttMultiBTC - rozszerzenie modeli EmoTweet i MultiBTC o warstwę atencji \n",
        "\n",
        "Każdy etap jest traktowany jako oddzielna lista na laboratorium, za którą można otrzymać 10 punktów. \n",
        "\n",
        "# Cel ćwiczenia\n",
        "\n",
        "Celem pierwszego etapu prac jest zapoznanie się z podstawową siecią rekurencyjną LSTM. Ze względu na fakt, że model ten będzie wykorzystany do analizy emocji tekstu, w ramach teorii do zadania zostanie omówiony podstawowy mechanizm konwersji słów w tekście do postaci wektorów dystrybucyjnych (tzw. word embeddings) na podstawie rozwiązania o nazwie `fastText`. Modele będą budowane na ogólnodostępnym zbiorze `TweetEval`, zawierającym podzbiory ręcznie anotowanych tweetów przy pomocy etykiet odnoszących się do następujących zjawisk: 1) emocje (emotion), 2) emotikony (emoji), 3) ironia (irony), 4) mowa nienawiści (hate speech), 5) mowa ofensywna (offensive language), 6) wydźwięk (sentiment), 7) nastawienie (stance). \n",
        "\n",
        "# Warunki zaliczenia\n",
        "\n",
        "Do zaliczenia pierwszego etapu należy utworzyć następujące modele dla min. 2 wybranych zjawisk:\n",
        "\n",
        "1.   Model bazowy (regresja logistyczna).\n",
        "2.   Model rekurencyjny oparty o sieć LSTM.\n",
        "\n",
        "Wytrenowane modele będą wykorzystane w 2 etapie, dlatego proszę je zachować.\n",
        "\n",
        "# Wektory dystrybucyjne\n",
        "\n",
        "W przetwarzaniu języka naturalnego, o wektorach dystrybucyjnych (inaczej osadzeniach lub zanurzeniach, ang. word embeddings) mówi się w kontekście reprezentacji słów w tekście, zazwyczaj w postaci wektora liczb rzeczywistych, który koduje znaczenie słowa. Hipoteza dystrybucyjna, u podstawy której leży większość metod reprezentacji, mówi o tym, że słowa, które często współwystępują, mają podobne znaczenie. Wektory dystrybucyjne można uzyskać za pomocą zestawu technik modelowania języka, w których słowa lub frazy są mapowane do wektorów liczb rzeczywistych. Z reguły polega to na matematycznym zanurzeniu z przestrzeni o wielu wymiarach opisujących słowo (konteksty) do ciągłej przestrzeni wektorowej o znacznie mniejszym wymiarze.\n",
        "\n",
        "Metody generowania tego odwzorowania obejmują sieci neuronowe, redukcję wymiarowości na macierzy współwystępowania słów, modele probabilistyczne lub jawną reprezentację w kontekście, w którym pojawiają się słowa. Wektory dystrybucyjne, używane jako podstawowa reprezentacja wejściowa tekstu, okazały się istotnie poprawiać jakość w wielu zadaniach NLP, takich jak np. rozpoznawanie nazw własnych, określanie części mowy, rozpoznawanie dziedziny tekstu, czy też rozpoznawanie wydźwięku i emocji w tekście. \n",
        "\n",
        "# fastText\n",
        "\n",
        "[fastText](https://fasttext.cc/) jest biblioteką do efektywnego uczenia modeli reprezentacji wektorowych słów oraz do budowania klasyfikatorów tekstu. Modele językowe można budować z wykorzystaniem dwóch popularnych technik: [Continuous Bag of Words](https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html) oraz [Skip-Gram](https://towardsdatascience.com/skip-gram-nlp-context-words-prediction-algorithm-5bbf34f84e0c). \n",
        "\n",
        "## Instalacja\n",
        "\n",
        "Pobranie repozytorium projektu:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UkMDUx6bn6e",
        "outputId": "90fe4d8e-2ca8-4450-b008-d1e3b82fcfd9"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3854, done.\u001b[K\n",
            "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3854/3854), 8.22 MiB | 16.61 MiB/s, done.\n",
            "Resolving deltas: 100% (2417/2417), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWc5Ie0cvYo"
      },
      "source": [
        "Instalacja biblioteki:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku0F_kKMbteg",
        "outputId": "539a4398-85cd-4121-ef67-1902c0ff2653"
      },
      "source": [
        "!cd fastText && mkdir build && cd build && cmake ..  && make && make install"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/fastText/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-static_pic\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/args.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/autotune.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/densematrix.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/dictionary.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/fasttext.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/loss.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/main.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/matrix.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/meter.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/model.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/productquantizer.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/quantmatrix.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/utils.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/vector.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32m\u001b[1mLinking CXX static library libfasttext_pic.a\u001b[0m\n",
            "[ 31%] Built target fasttext-static_pic\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-static\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/args.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/autotune.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/densematrix.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/dictionary.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/fasttext.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/loss.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/main.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/matrix.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/meter.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/model.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/productquantizer.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/quantmatrix.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/utils.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/vector.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX static library libfasttext.a\u001b[0m\n",
            "[ 63%] Built target fasttext-static\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-bin\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-bin.dir/src/main.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable fasttext\u001b[0m\n",
            "[ 68%] Built target fasttext-bin\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-shared\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/args.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/autotune.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/densematrix.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/dictionary.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/fasttext.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/loss.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/main.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/matrix.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/meter.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/model.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/productquantizer.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/quantmatrix.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/utils.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/vector.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library libfasttext.so\u001b[0m\n",
            "[100%] Built target fasttext-shared\n",
            "[ 31%] Built target fasttext-static_pic\n",
            "[ 63%] Built target fasttext-static\n",
            "[ 68%] Built target fasttext-bin\n",
            "[100%] Built target fasttext-shared\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Installing: /usr/local/lib/pkgconfig/fasttext.pc\n",
            "-- Installing: /usr/local/lib/libfasttext.so.0\n",
            "-- Installing: /usr/local/lib/libfasttext.so\n",
            "-- Installing: /usr/local/lib/libfasttext.a\n",
            "-- Installing: /usr/local/lib/libfasttext_pic.a\n",
            "-- Installing: /usr/local/bin/fasttext\n",
            "-- Installing: /usr/local/include/fasttext/args.h\n",
            "-- Installing: /usr/local/include/fasttext/autotune.h\n",
            "-- Installing: /usr/local/include/fasttext/densematrix.h\n",
            "-- Installing: /usr/local/include/fasttext/dictionary.h\n",
            "-- Installing: /usr/local/include/fasttext/fasttext.h\n",
            "-- Installing: /usr/local/include/fasttext/loss.h\n",
            "-- Installing: /usr/local/include/fasttext/matrix.h\n",
            "-- Installing: /usr/local/include/fasttext/meter.h\n",
            "-- Installing: /usr/local/include/fasttext/model.h\n",
            "-- Installing: /usr/local/include/fasttext/productquantizer.h\n",
            "-- Installing: /usr/local/include/fasttext/quantmatrix.h\n",
            "-- Installing: /usr/local/include/fasttext/real.h\n",
            "-- Installing: /usr/local/include/fasttext/utils.h\n",
            "-- Installing: /usr/local/include/fasttext/vector.h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ApV6Bzwc1_R"
      },
      "source": [
        "Instalacja API do Pythona:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xElxRxJycnDA",
        "outputId": "e14b64aa-b8d8-4cf0-99bc-2bb51b602e0b"
      },
      "source": [
        "!cd fastText && pip install ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (56.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3084658 sha256=0df50bf30a0cddf802c4d35659090a771554316217bc7d0080329c360ba31f51\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jq6bl71c/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ceW8c2XdOf4"
      },
      "source": [
        "# Dane do etapu nr 1\n",
        "\n",
        "## Korpus \n",
        "Korpus (zbiór dokumentów) do realizacji etapu nr 1 pochodzą z repozytorium [TweetEval](https://github.com/cardiffnlp/tweeteval). Repozytorium zawiera 7 różnorodnych zbiorów danych, zawierających zanonimizowane wpisy z [Twittera](https://twitter.com), anotowane następującymi zjawiskami: 1) emocje (emotion), 2) emotikony (emoji), 3) ironia (irony), 4) mowa nienawiści (hate speech), 5) mowa ofensywna (offensive language), 6) wydźwięk (sentiment), 7) nastawienie (stance). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER8c8zNmgE40",
        "outputId": "3f95470d-96c4-4fe1-ad3a-7c9d0b1f68e7"
      },
      "source": [
        "!wget http://jankocon.clarin-pl.eu/share/tweeteval.7z"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-05 06:14:27--  http://jankocon.clarin-pl.eu/share/tweeteval.7z\n",
            "Resolving jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)... 156.17.135.34\n",
            "Connecting to jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)|156.17.135.34|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17390348 (17M) [application/x-7z-compressed]\n",
            "Saving to: ‘tweeteval.7z’\n",
            "\n",
            "tweeteval.7z        100%[===================>]  16.58M   604 B/s    in 17s     \n",
            "\n",
            "2021-05-05 06:14:44 (975 KB/s) - ‘tweeteval.7z’ saved [17390348/17390348]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS6VxC26gUNt",
        "outputId": "bffbb270-b47a-448d-a899-9d353710f1ed"
      },
      "source": [
        "!7za x tweeteval.7z"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 17390348 bytes (17 MiB)\n",
            "\n",
            "Extracting archive: tweeteval.7z\n",
            "--\n",
            "Path = tweeteval.7z\n",
            "Type = 7z\n",
            "Physical Size = 17390348\n",
            "Headers Size = 1810\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 59% 66 - tweeteval/datasets/emoji/val_labels.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 33\n",
            "Files: 115\n",
            "Size:       30563155\n",
            "Compressed: 17390348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb6c5nuvgiaF"
      },
      "source": [
        "## Zawartość korpusu\n",
        "\n",
        "W katalogu głównym (tweeteval) znajdują się następujące elementy:\n",
        "*   `datasets` - katalog ze zbiorami danych\n",
        "   * `emotion` - tweety anotowane emocjami \n",
        "     * `mapping.txt` - identyfikatory etykiet oraz ich opis\n",
        "     * `train_text.txt` - wpisy z Twittera (część ucząca)\n",
        "     * `train_labels.txt` - etykiety wpisów z Twittera (część ucząca)\n",
        "     * `test_*.txt, valid_*.txt` - j.w. (część testowa i walidacyjna)\n",
        "   * `emoji` - tweety anotowane emotikonami\n",
        "   * `...` - katalogi zawierające tweety anotowane pozostałymi zjawiskami\n",
        "*   `predictions` - katalog z przykładowymi predykcjami\n",
        "   * `emotion.txt` - etykiety modelu predykcyjnego dla części testowej danych `emotion`\n",
        "   * `emoji.txt` - j.w. dla cz. testowej danych `emoji`\n",
        "   * `...` - j.w. dla pozostałych danych\n",
        "*   `evaluation_script.py` - skrypt do ewaluacji \n",
        "\n",
        "## Model języka\n",
        "\n",
        "Na potrzeby zadania został przygotowany model Skip-Gram reprezentacji wektorowej słów, zbudowany na wielkim korpusie tweetów dotyczących kursu BTC. Wersja binarna tego modelu dostępna jest w 2 wariantach:\n",
        "* [wektory 100-elementowe (1.7GB)](http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_100_en.bin)\n",
        "* [wektory 20-elementowe (350MB)](http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_20_en.bin)\n",
        "\n",
        "Na potrzeby prezentacji przykładowego rozwiązania zostanie wykorzystany mniejszy model. Do realizacji ostatecznego rozwiązania należy wykorzystać większy model. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stk-sYt9o6sD"
      },
      "source": [
        "# Model bazowy rozpoznawania emocji\n",
        "\n",
        "Model bazowy, zbudowany z wykorzystaniem narzędzia fastText (oparty o regresję logistyczną), będzie punktem wyjścia do porównania się z modelami opartymi o sieci LSTM, których skonstruowanie i ewaluacja na wybranych zadaniach będzie celem etapu nr 1. \n",
        "\n",
        "Pobranie mniejszego modelu reprezentacji języka tweetów:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChAehfcHggvF",
        "outputId": "d50b9d11-5b8f-4143-b4dc-db55761eb221"
      },
      "source": [
        "!wget http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_20_en.bin"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-05 06:14:45--  http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_20_en.bin\n",
            "Resolving jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)... 156.17.135.34\n",
            "Connecting to jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)|156.17.135.34|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 365240858 (348M) [application/octet-stream]\n",
            "Saving to: ‘fasttext_tweetmodel_btc_sg_20_en.bin’\n",
            "\n",
            "fasttext_tweetmodel 100%[===================>] 348.32M  11.2MB/s    in 33s     \n",
            "\n",
            "2021-05-05 06:15:18 (10.6 MB/s) - ‘fasttext_tweetmodel_btc_sg_20_en.bin’ saved [365240858/365240858]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkacglPdr96Y"
      },
      "source": [
        "Wydobycie słownika wektorów z binarnego modelu języka:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHyqkncyrZru"
      },
      "source": [
        "!python fastText/python/doc/examples/bin_to_vec.py fasttext_tweetmodel_btc_sg_20_en.bin > fasttext_tweetmodel_btc_sg_20_en.vec"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E_5UDKYyzwp"
      },
      "source": [
        "Dodanie prefiksu `__label__` do etykiet zbioru `emotion`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjUQvyKIsKV8"
      },
      "source": [
        "!sed 's/^/__label__/g' tweeteval/datasets/emotion/train_labels.txt > train_labels_emo.txt\n",
        "!sed 's/^/__label__/g' tweeteval/datasets/emotion/test_labels.txt > test_labels_emo.txt\n",
        "!sed 's/^/__label__/g' tweeteval/datasets/emotion/val_labels.txt > val_labels_emo.txt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlHv_VJ5zIHw"
      },
      "source": [
        "Przygotowanie zbioru uczącego, testowego i walidacyjnego w formacie `fastText`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNdjvsT8siZ1"
      },
      "source": [
        "!paste -d \" \" tweeteval/datasets/emotion/train_text.txt train_labels_emo.txt > train_emo.txt\n",
        "!paste -d \" \" tweeteval/datasets/emotion/test_text.txt test_labels_emo.txt > test_emo.txt\n",
        "!paste -d \" \" tweeteval/datasets/emotion/val_text.txt val_labels_emo.txt > val_emo.txt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro5A5HAEzGNJ"
      },
      "source": [
        "Trenowanie modelu z wykorzystaniem wejścia `train_emo.txt`, z określeniem wyjściowej nazwy modelu `emo_model`, dla wektorów słów o wymiarze `20`, z wykorzystaniem pretrenowanych wektorów z pliku `fasttext_tweetmodel_btc_sg_20_en.vec` i z uruchomieniem dostrajania hiperparametrów na zbiorze walidacyjnym `val_emo.txt`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GChCYj1ptoEj",
        "outputId": "103227ac-4cc6-4c37-8840-5611127cb188"
      },
      "source": [
        "!fasttext supervised -input train_emo.txt -output emo_model -dim 20 -pretrainedVectors fasttext_tweetmodel_btc_sg_20_en.vec -autotune-validation val_emo.txt "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : dim is manually set to a specific value. It will not be automatically optimized.\n",
            "Progress: 100.0% Trials:   16 Best score:  0.684492 ETA:   0h 0m 0s\n",
            "Training again with best arguments\n",
            "Read 0M words\n",
            "Number of words:  12887\n",
            "Number of labels: 4\n",
            "Progress: 100.0% words/sec/thread:   63409 lr:  0.000000 avg.loss:  0.041604 ETA:   0h 0m 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkp4BDnvzxrN"
      },
      "source": [
        "Podstawowa ewaluacja modelu z wykorzystaniem `fastText`, wynikiem jest precyzja (P - precision) i kompletność (R - recall) w wariancie [weighted](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90GbSCCgvmCj",
        "outputId": "def39261-9a9d-44da-e8aa-9f558abb8cee"
      },
      "source": [
        "!fasttext test emo_model.bin test_emo.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\t1421\n",
            "P@1\t0.681\n",
            "R@1\t0.681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoqaR5To0UWq"
      },
      "source": [
        "Rozszerzona ewaluacja modelu z wykorzystaniem `fastText`, wynikiem jest precyzja (P - precision), kompletność (R - recall) oraz F1-score dla każdej etykiety w wariancie [weighted](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3xFd-RDwv_w",
        "outputId": "e222f52f-7520-44ae-b0df-4719600a61a9"
      },
      "source": [
        "!fasttext test-label emo_model.bin test_emo.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score : 0.753289  Precision : 0.696049  Recall : 0.820789   __label__0\n",
            "F1-Score : 0.669312  Precision : 0.676471  Recall : 0.662304   __label__3\n",
            "F1-Score : 0.650602  Precision : 0.705882  Recall : 0.603352   __label__1\n",
            "F1-Score : 0.388350  Precision : 0.481928  Recall : 0.325203   __label__2\n",
            "N\t1421\n",
            "P@1\t0.681\n",
            "R@1\t0.681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y__FOjZO0jrw"
      },
      "source": [
        "Przygotowanie danych do ewaluacji z wykorzystaniem skryptu dołączonego do zbioru TweetEval:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZyri0pVw43n"
      },
      "source": [
        "!mkdir predictions2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gMgdnILxScS"
      },
      "source": [
        "!fasttext predict emo_model.bin tweeteval/datasets/emotion/test_text.txt | sed 's/__label__//g' > predictions2/emotion.txt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRwh9aIx0s3I"
      },
      "source": [
        "Uruchomienie ewaluacji. Oprócz wyników P, R, F1 [weighted]((https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)) dla każdej etykiety, otrzymujemy również wyniki w wariancie [macro]((https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)). **Ostateczną miarą (TweetEval Score) jest miara F1-score w wariancie macro i tę miarę proszę traktować jako kluczową przy porównywaniu rozwiązań.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpAjMNr2xn-e",
        "outputId": "1edf9aaf-6f2e-4ef5-e8c8-a117e75ac5b0"
      },
      "source": [
        "!python tweeteval/evaluation_script.py --tweeteval_path tweeteval/datasets --predictions_path predictions2 --task emotion"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'precision': 0.6960486322188449, 'recall': 0.8207885304659498, 'f1-score': 0.7532894736842105, 'support': 558}\n",
            "1 {'precision': 0.7058823529411765, 'recall': 0.6033519553072626, 'f1-score': 0.6506024096385542, 'support': 358}\n",
            "2 {'precision': 0.4819277108433735, 'recall': 0.3252032520325203, 'f1-score': 0.3883495145631068, 'support': 123}\n",
            "3 {'precision': 0.6764705882352942, 'recall': 0.662303664921466, 'f1-score': 0.6693121693121693, 'support': 382}\n",
            "accuracy 0.6805066854327938\n",
            "macro avg {'precision': 0.6400823210596722, 'recall': 0.6029118506817996, 'f1-score': 0.6153883917995102, 'support': 1421}\n",
            "weighted avg {'precision': 0.6747289882270753, 'recall': 0.6805066854327938, 'f1-score': 0.6732550513264621, 'support': 1421}\n",
            "------------------------------\n",
            "TweetEval Score (emotion): 0.6153883917995102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV9_Gnrz2T0m"
      },
      "source": [
        "# Budowa modeli EmoTweet\n",
        "\n",
        "W tej sekcji Państwa zadaniem będzie przygotowanie modeli sieci LSTM oraz modeli bazowych opartych o regresję logistyczną (fastText) dla wybranych 2 zjawisk ze zbioru TweetEval. Dla sieci LSTM kolejne jednostki sieci rekurencyjnej na wejściu dostają reprezentację wektorową kolejnych wyrazów w tekście. Wyjście z ostatniej jednostki podlega klasyfikacji. W celu usprawnienia zadania, przedstawiona zostanie metoda reprezentacji wektorowej tekstu z wykorzystaniem Pythonowego API do narzędzia fastText. Do ewaluacji modeli należy wykorzystać uprzednio zaprezentowany skrypt `tweeteval/evaluation_script.py`.\n",
        "\n",
        "## Wektoryzacja tekstu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmdakZza43X8"
      },
      "source": [
        "# inicjalizacja biblioteki\n",
        "import fasttext"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpJZYWyd6EK-"
      },
      "source": [
        "# ładowanie modelu\n",
        "MODEL_PATH = 'fasttext_tweetmodel_btc_sg_20_en.bin'\n",
        "model = fasttext.load_model(MODEL_PATH)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRs60cO96zk5"
      },
      "source": [
        "# wczytanie danych treningowych\n",
        "import pandas as pd\n",
        "TRAIN_PATH_EMO = 'tweeteval/datasets/emotion/train_text.txt'\n",
        "TEST_PATH_EMO = 'tweeteval/datasets/emotion/test_text.txt'"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6fdzMHHOlec"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m1h4fA-RFCS"
      },
      "source": [
        "def prepare_lstm_data(tweets_path, label_path):\n",
        "  texts = pd.read_csv(tweets_path, sep='\\t', header=None)\n",
        "  labels = pd.read_csv(label_path, sep='\\t', header=None)\n",
        "\n",
        "  assert len(texts) == len(labels)\n",
        "\n",
        "  training_data = []\n",
        "\n",
        "  for tweet in texts[0].tolist():\n",
        "    tweet_emb = []\n",
        "    for word in fasttext.tokenize(tweet):\n",
        "      tweet_emb.append(torch.tensor(model.get_word_vector(word).reshape(1, -1)))\n",
        "  \n",
        "    training_data.append(torch.cat(tweet_emb))\n",
        "  training_data_padded = torch.nn.utils.rnn.pad_sequence(training_data, batch_first=True)\n",
        "\n",
        "  labels_ints = torch.tensor([int(str_label[-1]) for  str_label in labels[0]])\n",
        "\n",
        "  return training_data_padded, labels_ints\n",
        "\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CN5pzQiSTPc",
        "outputId": "5efbda4b-c842-4c26-cbee-fee0cdb04a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "X_train_emo, y_train_emo = prepare_lstm_data(TRAIN_PATH_EMO, 'train_labels_emo.txt')\n",
        "X_test_emo, y_test_emo = prepare_lstm_data(TEST_PATH_EMO, 'test_labels_emo.txt')\n",
        "\n",
        "np.unique(y_train_emo)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1776ffa4135d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_emo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_emo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_lstm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH_EMO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_labels_emo.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_emo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_emo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_lstm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_PATH_EMO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_labels_emo.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_emo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prepare_lstm_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maNcSGc3WncH",
        "outputId": "602a69ae-5596-4f18-ea93-ba553f071063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_emo"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0, 1,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp_FGEotVqmf",
        "outputId": "fe468908-2edb-43d6-f54d-b622fc8953ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train_dataloader_emo = DataLoader(TensorDataset(X_train_emo, y_train_emo), batch_size=100)\n",
        "test_dataloader_emo = DataLoader(TensorDataset(X_test_emo, y_test_emo), batch_szie = 100)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17c742e98f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataloader_emo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_emo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_emo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataloader_emo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_emo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_emo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_szie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_emo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKEzzZTaSeOz"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWb5iv7T9ML9"
      },
      "source": [
        "Proszę zwrócić uwagę, że fastText jest w stanie przyporządkować reprezentację wektorową nawet dla takich słów, których model języka nie widział w trakcie uczenia (pierwszy token wejściowego tekstu). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYtFNcbU9qSR"
      },
      "source": [
        "## Model klasyfikacji tekstu LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOtB5TmlTMtM"
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOP5PoY7907f"
      },
      "source": [
        "class LSTMNet(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, classes):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.hidden2out = nn.Linear(hidden_dim, classes)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        _, (hn, cn) = self.lstm(sentence)\n",
        "        return self.hidden2out(hn.squeeze(dim=0))\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-FGUFOyTKzw",
        "outputId": "9b4035ce-6b5e-4c41-cb86-15dea9d147b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "082d021a10f242c1bedc807da13b2008",
            "1f57941c5e97403090ece9f37ae1ffbd",
            "4f5d7a00e4a54f8c921c82d409224f5c",
            "17e850ad96ae488c89a43ac12efac107",
            "452c6ae79c2746999de9c7be4efba04f",
            "36987f380f4841f9ab461ad564504e57",
            "5225a5f45fde40c78b7a1921c9444ad5",
            "5a40d1ae790948f185e559e959a16da7"
          ]
        }
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "def validate(\n",
        "    model: nn.Module, \n",
        "    loss_fn: torch.nn.CrossEntropyLoss, \n",
        "    dataloader: DataLoader):\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    all = 0\n",
        "    for X_batch, y_batch in tqdm(dataloader):\n",
        "        X_batch = X_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        y_pred = model(X_batch)\n",
        "        all += len(y_pred)\n",
        "        loss += loss_fn(y_pred, y_batch).sum()\n",
        "        correct += count_correct(y_pred, y_batch)\n",
        "    return loss / len(dataloader), correct / all\n",
        "\n",
        "def count_correct(\n",
        "    y_pred: torch.Tensor, y_true: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    preds = torch.argmax(y_pred, dim=1)\n",
        "   \n",
        "    return (preds == y_true).float().sum()\n",
        "\n",
        "def fit(\n",
        "    model: nn.Module, optimiser,\n",
        "    loss_fn: torch.nn.CrossEntropyLoss, train_dl: DataLoader, \n",
        "    val_dl: DataLoader, epochs: int, \n",
        "    print_metrics: str = True\n",
        "):\n",
        "\n",
        "    best_val_loss = float('inf') \n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        model.train()\n",
        "\n",
        "        for X_batch, y_batch in tqdm(train_dl):\n",
        "            X_batch = X_batch\n",
        "            y_batch = y_batch\n",
        "            y_pred = model(X_batch) # Uzyskanie pseudoprawdopodobieństw dla próbek z minibatcha\n",
        "            loss = loss_fn(y_pred, y_batch) # Policzenie funkcji straty\n",
        "            loss.backward() # Wsteczna propagacja z wyniku funkcji straty - policzenie gradientów i zapisanie ich w tensorach (parametrach)\n",
        "            optimiser.step() # Aktualizacja parametrów modelu przez optymalizator na podstawie gradientów zapisanych w tensorach (parametrach) oraz lr\n",
        "            optimiser.zero_grad() # Wyzerowanie gradientów w modelu, alternatywnie można wywołać percepron.zero_grad()\n",
        "        \n",
        "        if print_metrics: \n",
        "            model.eval() # Przełączenie na tryb ewaluacji modelu - istotne dla takich warstw jak Dropuot czy BatchNorm\n",
        "            with torch.no_grad():  # Wstrzymujemy przeliczanie i śledzenie gradientów dla tensorów - w procesie ewaluacji modelu nie chcemy zmian w gradientach\n",
        "                train_loss, train_acc = validate(model, loss_fn, train_dl)\n",
        "                val_loss, val_acc = validate(model, loss_fn, val_dl)\n",
        "                print(train_acc, val_acc)\n",
        "\n",
        "\n",
        "      \n",
        "    model.eval() # Przełączenie na tryb ewaluacji modelu - istotne dla takich warstw jak Dropuot czy BatchNorm\n",
        "    return     train_loss_history , train_acc_history ,val_loss_history ,val_acc_history\n",
        "    \n",
        "net = LSTMNet(20, 100, 4)\n",
        "optimiser = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "train_loss_history , train_acc_history ,val_loss_history ,val_acc_history = fit(\n",
        "    model=net, optimiser=optimiser, loss_fn=loss_fn, \n",
        "    train_dl=train_dataloader_emo, val_dl=test_dataloader_emo, epochs=50\n",
        ")\n",
        "test_loss, test_acc = validate(net, loss_fn, test_loader)\n",
        "print(f\"Test set evaluation: loss {test_loss}, acc {test_acc}\")\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "082d021a10f242c1bedc807da13b2008",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3257.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9E-pBUY90LF"
      },
      "source": [
        "## Trenowanie modeli LSTM dla ZJAWISKO_1 i ZJAWISKO_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Syr87r2-tSO"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvy1SbHQ-lFs"
      },
      "source": [
        "## Trenowanie modeli LR (fastText) dla ZJAWISKO_1 i ZJAWISKO_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V4g2jmv-weV"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8neBnDzU-4o9"
      },
      "source": [
        "## Ewaluacja modeli na danych testowych dla zjawiska ZJAWISKO_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wkbdG93_FxE"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIHyGqMM_HaE"
      },
      "source": [
        "## Ewaluacja modeli na danych testowych dla zjawiska ZJAWISKO_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ8yTGuu_Ird"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}